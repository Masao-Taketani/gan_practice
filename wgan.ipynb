{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svr0lCa0jHVy"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Masao-Taketani/gan_practice/blob/master/dcgan.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9sedAMzpTmQ"
   },
   "source": [
    "# The Difference Between WGAN and DCGAN\n",
    "- instead of the discriminator, people call it \"critic\"\n",
    "- uses Wasserstein Loss\n",
    "- 1 for real labels and -1 for fake labels\n",
    "- does not use the sigmoid activation for the final layer of the critic\n",
    "- clips the weights of the critic after each update\n",
    "- updates critic 5 times for each generator's update\n",
    "(which means the critic can learn things faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoJVq7aUjHV2"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization,\\\n",
    "Activation, Dropout, Flatten, Dense, Reshape, UpSampling2D, LeakyReLU,\\\n",
    "ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4ZDY3fjjHWD"
   },
   "outputs": [],
   "source": [
    "# hyper params\n",
    "img_size = 128\n",
    "channel_size = 3\n",
    "batch_size = 32\n",
    "\n",
    "input_dims = (img_size, img_size, channel_size)\n",
    "num_critic_layers = 4\n",
    "critic_conv_fils = [32, 64, 128, 256]\n",
    "critic_conv_kernel_size = [3, 3, 3, 3]\n",
    "critic_conv_strides = [2, 2, 2, 1]\n",
    "critic_batch_norm_momentum = 0.8\n",
    "critic_dropout_rate = 0.25\n",
    "\n",
    "z_dims = 100\n",
    "shape_after_dense = (img_size//4, img_size//4, 128)\n",
    "gen_upsamp_layers = [True, True, False]\n",
    "gen_batch_norm_momentum = 0.8\n",
    "gen_dropout_rate = None\n",
    "num_gen_layers = 3\n",
    "gen_conv_fils = [128, 64, channel_size]\n",
    "gen_conv_kernel_size = [3, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7t17X53-3AwY",
    "outputId": "77744157-bdab-4495-d988-4d27c342f86b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20590"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths = []\n",
    "\n",
    "#dataset_path = \"dataset/dog_data/\"\n",
    "dataset_path = \"drive/My Drive/dataset/gan/dog_imgs/\"\n",
    "img_dirs = glob(dataset_path + \"*\")\n",
    "for di in img_dirs:\n",
    "    imgs = glob(di + \"/*\")\n",
    "    for img in imgs:\n",
    "        img_paths.append(img)\n",
    "        \n",
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BZQPFivBWZUG",
    "outputId": "a5b40646-0c4a-48b9-9738-09fc2d71b6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "path: drive/My Drive/dataset/gan/dog_imgs/n02105855-Shetland_sheepdog/n02105855_2933.jpg\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "\n",
    "for i_path in img_paths:\n",
    "    img = Image.open(i_path)\n",
    "    resized_img = img.resize((img_size, img_size))\n",
    "    np_img = np.array(resized_img, dtype=np.float32)\n",
    "    if np_img.shape != (128, 128, 3):\n",
    "        print(\"Error\")\n",
    "        print(\"path:\", i_path)\n",
    "        continue\n",
    "    np_img = np_img / 127.5 - 1.0\n",
    "    x_train.append(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JM9nBmZzjHWA",
    "outputId": "1028b1bf-1b56-4739-c4d3-74606234d842"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20589, 128, 128, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TtNjH37UjHWG"
   },
   "source": [
    "## Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "PjVNAOwpjHWH",
    "outputId": "4f348efb-ebb7-475b-a0c9-c768cce259ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "critic_input = Input(shape=input_dims, name=\"critic_input\")\n",
    "x = critic_input\n",
    "\n",
    "for i in range(num_critic_layers):\n",
    "    x = Conv2D(filters=critic_conv_fils[i],\n",
    "              kernel_size=critic_conv_kernel_size[i],\n",
    "              strides=critic_conv_strides[i],\n",
    "              padding=\"same\",\n",
    "              name=\"critic_conv_\" + str(i)\n",
    "              )(x)\n",
    "    \n",
    "    if i == 1:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n",
    "        If int: the same symmetric padding is applied to height and width.\n",
    "        If tuple of 2 ints: interpreted as two different symmetric padding\n",
    "            values for height and width: (symmetric_height_pad, symmetric_width_pad).\n",
    "        If tuple of 2 tuples of 2 ints: interpreted \n",
    "            as ((top_pad, bottom_pad), (left_pad, right_pad))\n",
    "        \"\"\"\n",
    "        x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
    "        \n",
    "    if critic_batch_norm_momentum and i > 0:\n",
    "        x = BatchNormalization(momentum=critic_batch_norm_momentum)(x)\n",
    "        \n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    if critic_dropout_rate:\n",
    "        x = Dropout(critic_dropout_rate)(x)\n",
    "    \n",
    "x = Flatten()(x)\n",
    "critic_output = Dense(1, activation=None)(x)\n",
    "critic_model = Model(critic_input, critic_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "4gEeKTFbjHWJ",
    "outputId": "1324ecf8-c618-424e-f906-f5fd862ab503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "disc_input (InputLayer)      [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "disc_conv_0 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "disc_conv_1 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "disc_conv_2 (Conv2D)         (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "disc_conv_3 (Conv2D)         (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 464,193\n",
      "Trainable params: 463,297\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOLW7uELjHWN"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dySryfiFjHWN"
   },
   "outputs": [],
   "source": [
    "gen_input = Input(shape=(z_dims,), name=\"gen_input\")\n",
    "x = gen_input\n",
    "x = Dense(np.prod(shape_after_dense))(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Reshape(shape_after_dense)(x)\n",
    "for i in range(num_gen_layers):\n",
    "    if gen_upsamp_layers[i]:\n",
    "        x = UpSampling2D()(x)\n",
    "        \n",
    "    x = Conv2D(gen_conv_fils[i],\n",
    "              gen_conv_kernel_size[i],\n",
    "              padding=\"same\",\n",
    "              name=\"gen_conv_\" + str(i)\n",
    "              )(x)\n",
    "    \n",
    "    if i < num_gen_layers - 1:\n",
    "        if gen_batch_norm_momentum:\n",
    "            x = BatchNormalization(\n",
    "            momentum=gen_batch_norm_momentum)(x)\n",
    "            \n",
    "        x = Activation(\"relu\")(x)\n",
    "    else:\n",
    "        x = Activation(\"tanh\")(x)\n",
    "        \n",
    "gen_output = x\n",
    "gen_model = Model(gen_input, gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "yacwHHYijHWQ",
    "outputId": "5fc81b3d-a5ca-4ef7-f33b-aeb5f371b1ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gen_input (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "gen_conv_0 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "gen_conv_1 (Conv2D)          (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "gen_conv_2 (Conv2D)          (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,147\n",
      "Trainable params: 13,461,763\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkR6V7RcHxBR"
   },
   "source": [
    "# Wasserstein Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8k8jI8AZHvOI"
   },
   "outputs": [],
   "source": [
    "def wasserstein(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkWHS_GujHWS"
   },
   "source": [
    "## Train the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRs0OP7kjHWT"
   },
   "source": [
    "### compile critic train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "-WH5Pr5yjHWU",
    "outputId": "9be0c6cd-7849-412c-b736-de2ef0f2b0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "critic_model.compile(optimizer=RMSprop(lr=0.00005),\n",
    "                  #optimizer=Adam(0.0002, 0.5),\n",
    "                  loss=wasserstein,\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "djYZgDcrjHWX",
    "outputId": "1bc33f1b-90c0-4170-8aaa-dcdc92cf27fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "comb_model_input (InputLayer [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 128, 128, 3)       13462147  \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 1)                 464193    \n",
      "=================================================================\n",
      "Total params: 13,926,340\n",
      "Trainable params: 13,461,763\n",
      "Non-trainable params: 464,577\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# freeze the critic_riminator model so that it only makes\n",
    "# the generator model train on this model\n",
    "critic_model.trainable = False\n",
    "comb_model_input = Input(shape=(z_dims,), name=\"comb_model_input\")\n",
    "comb_model_output = critic_model(gen_model(comb_model_input))\n",
    "comb_model = Model(comb_model_input, comb_model_output)\n",
    "comb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hEV9TQQjHWa"
   },
   "source": [
    "### compile generator train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyjYq695jHWa"
   },
   "outputs": [],
   "source": [
    "comb_model.compile(optimizer=RMSprop(0.00005),\n",
    "             #optimizer=Adam(0.0002, 0.5),\n",
    "             loss=wasserstein,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClsLux-4jHWd"
   },
   "outputs": [],
   "source": [
    "def train_critic(critic_model, gen_model, x_train, batch_size):\n",
    "    # create 2-dim labels\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = -np.ones((batch_size, 1))\n",
    "    \n",
    "    # train on real imgs\n",
    "    # np.random.randint(min, max, size)\n",
    "    idxes = np.random.randint(0, len(x_train), batch_size)\n",
    "    real_imgs = x_train[idxes]\n",
    "    \n",
    "    critic_real_loss = critic_model.train_on_batch(real_imgs, real_labels)\n",
    "    \n",
    "    # train on fake imgs\n",
    "    # np.random.normal(mean, std, size)\n",
    "    # the blow follows the standard normal distribution\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "    fake_imgs = gen_model.predict(noise)\n",
    "    \n",
    "    critic_fake_loss = critic_model.train_on_batch(fake_imgs, fake_labels)\n",
    "\n",
    "    # weights clipping\n",
    "    for l in critic_model.layers:\n",
    "        weights = l.get_weights()\n",
    "        weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "        l.set_weights(weights)\n",
    "    critic_loss = 0.5 * np.add(critic_real_loss, critic_fake_loss)\n",
    "    return critic_loss\n",
    "\n",
    "\n",
    "def train_gen(comb_model, batch_size):\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "    \n",
    "    gen_loss = comb_model.train_on_batch(noise, real_labels)\n",
    "    return gen_loss\n",
    "\n",
    "\n",
    "def plot_generated_imgs(rows, cols, noises, it, gen_model):\n",
    "    print(\"iteration: \", it)\n",
    "\n",
    "    gen_imgs = gen_model.predict(noises)\n",
    "\n",
    "    # since gen model outputs values ranging from -1 to 1,\n",
    "    # nomalize imgs ranging from 0 to 1\n",
    "    #=====================================================================\n",
    "    # matplotlib.pyplot.imshow(..., norm=None, ...):\n",
    "    # By default, a linear scaling mapping the lowest value to 0 and\n",
    "    # the highest to 1 is used. This parameter is ignored for RGB(A) data.\n",
    "    #=====================================================================\n",
    "\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols)\n",
    "\n",
    "    ith_img = 0\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            try:\n",
    "                axs[row, col].imshow(gen_imgs[ith_img,:,:,:])\n",
    "                axs[row, col].axis(\"off\")\n",
    "                ith_img += 1\n",
    "            except IndexError:\n",
    "                axs[col].imshow(gen_imgs[ith_img,:,:,:])\n",
    "                axs[col].axis(\"off\")\n",
    "                ith_img += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "JosF9dJVjHWl",
    "outputId": "d2735beb-d48a-4a27-b43b-f81c297336be",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training log]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "iteration: 0 disc loss: 2.635599, disc acc: 18.75% | gen loss: 0.178372, gen acc: 0.97%\n",
      "iteration:  0\n",
      "iteration: 1000 disc loss: 0.258594, disc acc: 90.62% | gen loss: 0.564881, gen acc: 0.78%\n",
      "iteration:  1000\n",
      "iteration: 2000 disc loss: 0.553202, disc acc: 70.31% | gen loss: 0.344697, gen acc: 0.88%\n",
      "iteration:  2000\n",
      "iteration: 3000 disc loss: 1.317289, disc acc: 48.44% | gen loss: 1.257062, gen acc: 0.28%\n",
      "iteration:  3000\n",
      "iteration: 4000 disc loss: 0.515059, disc acc: 71.88% | gen loss: 1.414170, gen acc: 0.22%\n",
      "iteration:  4000\n",
      "iteration: 5000 disc loss: 0.458918, disc acc: 79.69% | gen loss: 1.047156, gen acc: 0.41%\n",
      "iteration:  5000\n",
      "iteration: 6000 disc loss: 0.300063, disc acc: 92.19% | gen loss: 0.335218, gen acc: 0.94%\n",
      "iteration:  6000\n",
      "iteration: 7000 disc loss: 0.921092, disc acc: 50.00% | gen loss: 1.342178, gen acc: 0.22%\n",
      "iteration:  7000\n",
      "iteration: 8000 disc loss: 0.863422, disc acc: 56.25% | gen loss: 1.340371, gen acc: 0.31%\n",
      "iteration:  8000\n",
      "iteration: 9000 disc loss: 0.440706, disc acc: 87.50% | gen loss: 1.258740, gen acc: 0.34%\n",
      "iteration:  9000\n",
      "iteration: 10000 disc loss: 1.157100, disc acc: 54.69% | gen loss: 1.072025, gen acc: 0.38%\n",
      "iteration:  10000\n",
      "iteration: 11000 disc loss: 0.356398, disc acc: 84.38% | gen loss: 1.510093, gen acc: 0.31%\n",
      "iteration:  11000\n",
      "iteration: 12000 disc loss: 1.023181, disc acc: 45.31% | gen loss: 2.371245, gen acc: 0.03%\n",
      "iteration:  12000\n",
      "iteration: 13000 disc loss: 0.457567, disc acc: 75.00% | gen loss: 2.860354, gen acc: 0.06%\n",
      "iteration:  13000\n",
      "iteration: 14000 disc loss: 0.424465, disc acc: 78.12% | gen loss: 1.978119, gen acc: 0.19%\n",
      "iteration:  14000\n",
      "iteration: 15000 disc loss: 0.891018, disc acc: 56.25% | gen loss: 2.843063, gen acc: 0.06%\n",
      "iteration:  15000\n"
     ]
    }
   ],
   "source": [
    "iterations = 20_000\n",
    "rows, cols = 2, 5\n",
    "noises = np.random.normal(0, 1, (rows * cols, z_dims))\n",
    "\n",
    "print(\"[training log]\")\n",
    "for it in range(iterations):\n",
    "\n",
    "    for i in range(5):\n",
    "        if i == 4:\n",
    "            critic_loss = train_critic(critic_model, gen_model, x_train, batch_size)\n",
    "        else:\n",
    "            _ = train_critic(critic_model, gen_model, x_train, batch_size)\n",
    "    \n",
    "    gen_loss = train_gen(comb_model, batch_size)\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(\"iteration: %d critic_ loss: %f, critic_ acc: %.2f%% | gen loss: %f, \"\n",
    "        \"gen acc: %.2f%%\" % \n",
    "          (it, critic_loss[0], 100 * critic_loss[1], gen_loss[0], gen_loss[1]))\n",
    "        plot_generated_imgs(rows, cols, noises, it, gen_model)\n",
    "        \n",
    "print(\"[10 generated images for each 1000th iteration]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uu5NCGJvvFvi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "dcgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
