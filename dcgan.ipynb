{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, BatchNormalization,\\\n",
    "Activation, Dropout, Flatten, Dense, Reshape, UpSampling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "from keras.initializers import RandomNormal\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train/127.5 - 1\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "input_dims = (28, 28, 1)\n",
    "num_disc_layers = 4\n",
    "disc_conv_fils = [64, 64, 128, 128]\n",
    "disc_conv_kernel_size = [5, 5, 5, 5]\n",
    "disc_conv_strides = [2, 2, 2, 1]\n",
    "disc_batch_norm_momentum = None\n",
    "disc_dropout_rate = 0.4\n",
    "\n",
    "z_dims = 100\n",
    "shape_after_dense = (7, 7, 64)\n",
    "upsamp_layers = [True, True, False, False]\n",
    "gen_batch_norm_momentum = 0.9\n",
    "gen_dropout_rate = None\n",
    "num_gen_layers = 4\n",
    "gen_conv_fils = [128, 64, 64, 1]\n",
    "gen_conv_kernel_size = [5, 5, 5, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_input = Input(shape=input_dims, name=\"disc_input\")\n",
    "x = disc_input\n",
    "\n",
    "for i in range(num_disc_layers):\n",
    "    x = Conv2D(filters=disc_conv_fils[i],\n",
    "              kernel_size=disc_conv_kernel_size[i],\n",
    "              strides=disc_conv_strides[i],\n",
    "              padding=\"same\",\n",
    "              name=\"disc_conv_\" + str(i)\n",
    "              )(x)\n",
    "    \n",
    "    if disc_batch_norm_momentum and i > 0:\n",
    "        x = BatchNormalization(momentum=disc_batch_norm_momentum)(x)\n",
    "        \n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    if disc_dropout_rate:\n",
    "        x = Dropout(disc_dropout_rate)(x)\n",
    "    \n",
    "x = Flatten()(x)\n",
    "disc_output = Dense(1, activation=\"sigmoid\", \\\n",
    "                    kernel_initializer=RandomNormal(mean=0., stddev=0.02))(x)\n",
    "disc_model = Model(disc_input, disc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "disc_input (InputLayer)      (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "disc_conv_0 (Conv2D)         (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "disc_conv_1 (Conv2D)         (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "disc_conv_2 (Conv2D)         (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "disc_conv_3 (Conv2D)         (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = Input(shape=(z_dims,), name=\"gen_input\")\n",
    "x = gen_input\n",
    "x = Dense(np.prod(shape_after_dense))(x)\n",
    "\n",
    "if gen_batch_norm_momentum:\n",
    "    x = BatchNormalization(momentum=gen_batch_norm_momentum)(x)\n",
    "    \n",
    "x = Activation(\"relu\")(x)\n",
    "x = Reshape(shape_after_dense)(x)\n",
    "\n",
    "if gen_dropout_rate:\n",
    "    x = Dropout(rate=gen_dropout_rate)(x)\n",
    "    \n",
    "for i in range(num_gen_layers):\n",
    "    if upsamp_layers[i]:\n",
    "        x = UpSampling2D()(x)\n",
    "        \n",
    "    x = Conv2D(gen_conv_fils[i],\n",
    "              gen_conv_kernel_size[i],\n",
    "              padding=\"same\",\n",
    "              name=\"gen_conv_\" + str(i)\n",
    "              )(x)\n",
    "    \n",
    "    if i < num_gen_layers - 1:\n",
    "        if gen_batch_norm_momentum:\n",
    "            x = BatchNormalization(\n",
    "            momentum=gen_batch_norm_momentum)(x)\n",
    "            \n",
    "        x = Activation(\"relu\")(x)\n",
    "    else:\n",
    "        x = Activation(\"tanh\")(x)\n",
    "        \n",
    "gen_output = x\n",
    "gen_model = Model(gen_input, gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gen_input (InputLayer)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "gen_conv_0 (Conv2D)          (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "gen_conv_1 (Conv2D)          (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "gen_conv_2 (Conv2D)          (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "gen_conv_3 (Conv2D)          (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile discriminator train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_model.compile(optimizer=RMSprop(lr=0.0008),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the discriminator model so that it only makes\n",
    "# the generator model train on this model\n",
    "disc_model.trainable = False\n",
    "comb_model_input = Input(shape=(z_dims,), name=\"comb_model_input\")\n",
    "comb_model_output = disc_model(gen_model(comb_model_input))\n",
    "comb_model = Model(comb_model_input, comb_model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile generator train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model.compile(optimizer=RMSprop(0.0004),\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_disc(disc_model, gen_model, x_train, batch_size):\n",
    "    # create 2-dim labels\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.ones((batch_size, 1))\n",
    "    \n",
    "    # train on real imgs\n",
    "    # np.random.randint(min, max, size)\n",
    "    idxes = np.random.randint(0, len(x_train), batch_size)\n",
    "    real_imgs = x_train[idxes]\n",
    "    \n",
    "    disc_model.train_on_batch(real_imgs, real_labels)\n",
    "    \n",
    "    # train on fake imgs\n",
    "    # np.random.normal(mean, std, size)\n",
    "    # the blow follows the standard normal distribution\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "    fake_imgs = gen_model.predict(noise)\n",
    "    \n",
    "    disc_model.train_on_batch(fake_imgs, fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(comb_model, batch_size):\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "    \n",
    "    comb_model.train_on_batch(noise, real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_img(noise):\n",
    "    result_img = gen_model.predict(noise)\n",
    "    reshaped_img = np.reshape(result_img, list(input_dims[:2]))\n",
    "    orig_form_img = 127.5 * (reshaped_img + 1.0)\n",
    "    pil_img = Image.fromarray(orig_form_img)\n",
    "    plt.imshow(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 1000\n",
      "epoch 2000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = 3000\n",
    "batch_size = 64\n",
    "test_noise = np.random.normal(0, 1, (1, z_dims))\n",
    "\n",
    "for it in range(iterations):\n",
    "    train_disc(disc_model, gen_model, x_train, batch_size)\n",
    "    train_gen(comb_model, batch_size)\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(\"epoch {}\".format(it))\n",
    "        plot_generated_img(test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
