{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svr0lCa0jHVy"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Masao-Taketani/gan_practice/blob/master/dcgan.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoJVq7aUjHV2"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization,\\\n",
    "Activation, Dropout, Flatten, Dense, Reshape, UpSampling2D, LeakyReLU,\\\n",
    "ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7t17X53-3AwY",
    "outputId": "7d1cdee8-967e-4e1c-c41a-d0739ff12d06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20580"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths = []\n",
    "\n",
    "dataset_path = \"dataset/dog_data/\"\n",
    "img_dirs = glob(dataset_path + \"*\")\n",
    "for di in img_dirs:\n",
    "    imgs = glob(di + \"/*\")\n",
    "    for img in imgs:\n",
    "        img_paths.append(img)\n",
    "        \n",
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "path: dataset/dog_data/n02105855-Shetland_sheepdog/n02105855_2933.jpg\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "img_size = 128\n",
    "\n",
    "for i_path in img_paths:\n",
    "    img = Image.open(i_path)\n",
    "    resized_img = img.resize((img_size, img_size))\n",
    "    np_img = np.array(resized_img, dtype=np.float32)\n",
    "    if np_img.shape != (128, 128, 3):\n",
    "        print(\"Error\")\n",
    "        print(\"path:\", i_path)\n",
    "        continue\n",
    "    np_img = np_img / 127.5 - 1.0\n",
    "    x_train.append(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM9nBmZzjHWA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20579, 128, 128, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4ZDY3fjjHWD"
   },
   "outputs": [],
   "source": [
    "# hyper params\n",
    "channel_size = 3\n",
    "input_dims = (img_size, img_size, channel_size)\n",
    "num_disc_layers = 4\n",
    "disc_conv_fils = [32, 64, 128, 256]\n",
    "disc_conv_kernel_size = [3, 3, 3, 3]\n",
    "disc_conv_strides = [2, 2, 2, 1]\n",
    "disc_batch_norm_momentum = 0.8\n",
    "disc_dropout_rate = 0.25\n",
    "\n",
    "z_dims = 100\n",
    "shape_after_dense = (img_size//4, img_size//4, 128)\n",
    "gen_upsamp_layers = [True, True, False]\n",
    "gen_batch_norm_momentum = 0.8\n",
    "gen_dropout_rate = None\n",
    "num_gen_layers = 3\n",
    "gen_conv_fils = [128, 64, channel_size]\n",
    "gen_conv_kernel_size = [3, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TtNjH37UjHWG"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "PjVNAOwpjHWH",
    "outputId": "a33f0180-b8b3-41cd-9380-5669b04a44c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0209 22:54:33.085552 140099936065280 deprecation.py:506] From /home/m-taketani/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "disc_input = Input(shape=input_dims, name=\"disc_input\")\n",
    "x = disc_input\n",
    "\n",
    "for i in range(num_disc_layers):\n",
    "    x = Conv2D(filters=disc_conv_fils[i],\n",
    "              kernel_size=disc_conv_kernel_size[i],\n",
    "              strides=disc_conv_strides[i],\n",
    "              padding=\"same\",\n",
    "              name=\"disc_conv_\" + str(i)\n",
    "              )(x)\n",
    "    \n",
    "    if i == 1:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n",
    "        If int: the same symmetric padding is applied to height and width.\n",
    "        If tuple of 2 ints: interpreted as two different symmetric padding\n",
    "            values for height and width: (symmetric_height_pad, symmetric_width_pad).\n",
    "        If tuple of 2 tuples of 2 ints: interpreted \n",
    "            as ((top_pad, bottom_pad), (left_pad, right_pad))\n",
    "        \"\"\"\n",
    "        x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
    "        \n",
    "    if disc_batch_norm_momentum and i > 0:\n",
    "        x = BatchNormalization(momentum=disc_batch_norm_momentum)(x)\n",
    "        \n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    if disc_dropout_rate:\n",
    "        x = Dropout(disc_dropout_rate)(x)\n",
    "    \n",
    "x = Flatten()(x)\n",
    "disc_output = Dense(1, activation=\"sigmoid\")(x)\n",
    "disc_model = Model(disc_input, disc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "4gEeKTFbjHWJ",
    "outputId": "0d21681a-0571-4f99-fce2-533fbae80a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "disc_input (InputLayer)      [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "disc_conv_0 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "disc_conv_1 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "disc_conv_2 (Conv2D)         (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "disc_conv_3 (Conv2D)         (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 464,193\n",
      "Trainable params: 463,297\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOLW7uELjHWN"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dySryfiFjHWN"
   },
   "outputs": [],
   "source": [
    "gen_input = Input(shape=(z_dims,), name=\"gen_input\")\n",
    "x = gen_input\n",
    "x = Dense(np.prod(shape_after_dense))(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Reshape(shape_after_dense)(x)\n",
    "for i in range(num_gen_layers):\n",
    "    if gen_upsamp_layers[i]:\n",
    "        x = UpSampling2D()(x)\n",
    "        \n",
    "    x = Conv2D(gen_conv_fils[i],\n",
    "              gen_conv_kernel_size[i],\n",
    "              padding=\"same\",\n",
    "              name=\"gen_conv_\" + str(i)\n",
    "              )(x)\n",
    "    \n",
    "    if i < num_gen_layers - 1:\n",
    "        if gen_batch_norm_momentum:\n",
    "            x = BatchNormalization(\n",
    "            momentum=gen_batch_norm_momentum)(x)\n",
    "            \n",
    "        x = Activation(\"relu\")(x)\n",
    "    else:\n",
    "        x = Activation(\"tanh\")(x)\n",
    "        \n",
    "gen_output = x\n",
    "gen_model = Model(gen_input, gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "yacwHHYijHWQ",
    "outputId": "dbb6e93f-e715-4e2f-d1f4-b35b8fb4c981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gen_input (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "gen_conv_0 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "gen_conv_1 (Conv2D)          (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "gen_conv_2 (Conv2D)          (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,147\n",
      "Trainable params: 13,461,763\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkWHS_GujHWS"
   },
   "source": [
    "## Train the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRs0OP7kjHWT"
   },
   "source": [
    "### compile discriminator train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "-WH5Pr5yjHWU",
    "outputId": "1de57882-ce9e-4482-d1b3-c5a496f7281f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0209 22:54:33.710886 140099936065280 deprecation.py:323] From /home/m-taketani/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "disc_model.compile(#optimizer=RMSprop(lr=0.0008),\n",
    "                  optimizer=Adam(0.0002, 0.5),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djYZgDcrjHWX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "comb_model_input (InputLayer [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 128, 128, 3)       13462147  \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 1)                 464193    \n",
      "=================================================================\n",
      "Total params: 13,926,340\n",
      "Trainable params: 13,461,763\n",
      "Non-trainable params: 464,577\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# freeze the discriminator model so that it only makes\n",
    "# the generator model train on this model\n",
    "disc_model.trainable = False\n",
    "comb_model_input = Input(shape=(z_dims,), name=\"comb_model_input\")\n",
    "comb_model_output = disc_model(gen_model(comb_model_input))\n",
    "comb_model = Model(comb_model_input, comb_model_output)\n",
    "comb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hEV9TQQjHWa"
   },
   "source": [
    "### compile generator train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyjYq695jHWa"
   },
   "outputs": [],
   "source": [
    "comb_model.compile(#optimizer=RMSprop(0.0004),\n",
    "             optimizer=Adam(0.0002, 0.5),\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClsLux-4jHWd"
   },
   "outputs": [],
   "source": [
    "def train_disc(disc_model, gen_model, x_train, batch_size):\n",
    "    # create 2-dim labels\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "    \n",
    "    # train on real imgs\n",
    "    # np.random.randint(min, max, size)\n",
    "    idxes = np.random.randint(0, len(x_train), batch_size)\n",
    "    real_imgs = x_train[idxes]\n",
    "    \n",
    "    disc_real_loss = disc_model.train_on_batch(real_imgs, real_labels)\n",
    "    \n",
    "    # train on fake imgs\n",
    "    # np.random.normal(mean, std, size)\n",
    "    # the blow follows the standard normal distribution\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "    fake_imgs = gen_model.predict(noise)\n",
    "    \n",
    "    disc_fake_loss = disc_model.train_on_batch(fake_imgs, fake_labels)\n",
    "    disc_loss = 0.5 * np.add(disc_real_loss, disc_fake_loss)\n",
    "    return disc_loss\n",
    "\n",
    "\n",
    "def train_gen(comb_model, batch_size):\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "    \n",
    "    gen_loss = comb_model.train_on_batch(noise, real_labels)\n",
    "    return gen_loss\n",
    "\n",
    "\n",
    "def plot_generated_imgs(rows, cols, noises, it, gen_model):\n",
    "    print(\"iteration: \", it)\n",
    "\n",
    "    gen_imgs = gen_model.predict(noises)\n",
    "\n",
    "    # since gen model outputs values ranging from -1 to 1,\n",
    "    # nomalize imgs ranging from 0 to 1\n",
    "    #=====================================================================\n",
    "    # matplotlib.pyplot.imshow(..., norm=None, ...):\n",
    "    # By default, a linear scaling mapping the lowest value to 0 and\n",
    "    # the highest to 1 is used. This parameter is ignored for RGB(A) data.\n",
    "    #=====================================================================\n",
    "\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols)\n",
    "\n",
    "    ith_img = 0\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            try:\n",
    "                axs[row, col].imshow(gen_imgs[ith_img,:,:,0], cmap=\"gray\")\n",
    "                axs[row, col].axis(\"off\")\n",
    "                ith_img += 1\n",
    "            except IndexError:\n",
    "                axs[col].imshow(gen_imgs[ith_img,:,:,0], cmap=\"gray\")\n",
    "                axs[col].axis(\"off\")\n",
    "                ith_img += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JosF9dJVjHWl",
    "outputId": "64a772af-a061-4c29-8ce7-dfb388fab1a8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training log]\n",
      "noise: (1, 100)\n",
      "real_labels: (1, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'dense_target' with dtype float and shape [?,?]\n\t [[{{node dense_target}}]]\n\t [[loss_2/mul/_369]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'dense_target' with dtype float and shape [?,?]\n\t [[{{node dense_target}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2e6b2ec103f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#gen_loss = train_gen(comb_model, batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-e27d4957d7ff>\u001b[0m in \u001b[0;36mtrain_gen\u001b[0;34m(comb_model, batch_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"real_labels:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'dense_target' with dtype float and shape [?,?]\n\t [[{{node dense_target}}]]\n\t [[loss_2/mul/_369]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'dense_target' with dtype float and shape [?,?]\n\t [[{{node dense_target}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "iterations = 20_000\n",
    "batch_size = 1\n",
    "rows, cols = 1, 5\n",
    "noises = np.random.normal(0, 1, (rows * cols, z_dims))\n",
    "\n",
    "print(\"[training log]\")\n",
    "for it in range(iterations):\n",
    "    disc_loss = train_disc(disc_model, gen_model, x_train, batch_size)\n",
    "    gen_loss = train_gen(comb_model, batch_size)\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(\"iteration: %d disc loss: %f, disc acc: %.2f%% | gen loss: %f, \"\n",
    "        \"gen acc: %.2f%%\" % \n",
    "          (it, disc_loss[0], 100 * disc_loss[1], gen_loss[0], gen_loss[1]))\n",
    "        plot_generated_imgs(rows, cols, noises, it, gen_model)\n",
    "        \n",
    "print(\"[5 generated images for each 1000th iteration]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uu5NCGJvvFvi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "dcgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
